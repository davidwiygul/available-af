# airflow
#!/bin/bash


source provision.config

ssh -T -i $AWS_SSH_KEY ubuntu@$1 << HERE
    sudo apt-get install -y python3-pip

    python3 -m pip install riak

    python3 -m pip install pipdeptree

    python3 -m pip install psycopg2-binary

    python3 -m pip install werkzeug==0.16.0

    python3 -m pip install apache-airflow[postgres,celery]

    source .profile

   airflow initdb

    declare -A dict=(
        [dags_folder]=$EFS_PATH/dags
        [sql_alchemy_conn]=postgresql+psycopg2://$DB_USER:$DB_PWD@$DB_IP/$DATABASE
        [executor]=CeleryExecutor
        [broker_url]=pyamqp://$QUEUE_USER:$QUEUE_PWD@$MQ_IP:5672/$QUEUE_HOST
        [result_backend]=db+postgresql://$DB_USER:$DB_PWD@$DB_IP/$DATABASE
 	#[parallelism]=32
	#[dag_concurrency]=32
	#[worker_concurrency]=8
	#[worker_autoscale]=8,8
)

    for key in \${!dict[@]}; do
        value=\${dict[\$key]}
        sed -i "s|\(^\$key\).*|\1 = \$value|" ~/airflow/airflow.cfg
    done

    airflow initdb

    exit


HERE
