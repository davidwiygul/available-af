# provision_multischeduler
#!/bin/bash

source provision.config

ssh -i $AWS_SSH_KEY ubuntu@$1 sudo apt-get update
./efs $1
./airflow $1
ssh -i $AWS_SSH_KEY ubuntu@$1 python3 -m pip install pika

declare -A dict=(
    [db_ip]=$DB_IP
    [database]=$DATABASE
    [db_user]=$DB_USER
    [db_pwd]=$DB_PWD
    [q_ip]=$MQ_IP
    [q_user]=$NEWS_QUEUE_USER
    [q_pwd]=$NEWS_QUEUE_PWD
    [q_vhost]=$NEWS_QUEUE_VHOST
    )

for key in ${!dict[@]}; do
    value=${dict[$key]}
    sed -i "s|\(^$key\).*|\1 = $value|" ../heirflow/multischeduler.ini
done

ssh -i $AWS_SSH_KEY ubuntu@$1 mkdir /home/ubuntu/multischeduler
scp -i $AWS_SSH_KEY ../heirflow/multischeduler.py ubuntu@$1:/home/ubuntu/multischeduler/
scp -i $AWS_SSH_KEY ../heirflow/multischeduler.ini ubuntu@$1:/home/ubuntu/multischeduler/
scp -i $AWS_SSH_KEY ../heirflow/hfshared.py ubuntu@$1:/home/ubuntu/multischeduler/

./daemonize airflow-multischeduler $1
